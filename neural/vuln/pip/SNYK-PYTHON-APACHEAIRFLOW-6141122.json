{
    "CVSSv3": {
        "CVSS": "3.1",
        "attackVector": "NETWORK",
        "attackComplexity": "LOW",
        "privilegesRequired": "LOW",
        "userInteraction": "NONE",
        "scope": "UNCHANGED",
        "confidentiality": "NONE",
        "integrity": "NONE",
        "availability": "LOW"
    },
    "credit": [
        "Unknown"
    ],
    "cvssDetails": [
        {
            "assigner": "NVD",
            "cvssV3BaseScore": 6.5,
            "cvssV3Vector": {
                "CVSS": "3.1",
                "attackVector": "NETWORK",
                "attackComplexity": "LOW",
                "privilegesRequired": "LOW",
                "userInteraction": "NONE",
                "scope": "UNCHANGED",
                "confidentiality": "NONE",
                "integrity": "NONE",
                "availability": "HIGH"
            },
            "severity": "medium"
        }
    ],
    "cvssScore": 4.3,
    "disclosureTime": "2024-01-01 06:27:27",
    "epssDetails": {
        "modelVersion": "v2023.03.01",
        "percentile": "0.08197",
        "probability": "0.00044"
    },
    "exploitMaturity": "Not Defined",
    "id": "SNYK-PYTHON-APACHEAIRFLOW-6141122",
    "identifiers": {
        "CVE": [
            "CVE-2023-22888"
        ],
        "CWE": [
            "CWE-400"
        ]
    },
    "language": "python",
    "malicious": false,
    "packageManager": "pip",
    "publicationTime": "2024-01-01 11:07:18",
    "remediation": "Upgrade apache-airflow to version 2.6.3 or higher. ",
    "severity": "medium",
    "socialTrendAlert": false,
    "title": "Denial of Service (DoS)",
    "vulnDescription": {
        "Details": "Denial of Service (DoS) describes a family of attacks, all aimed at making a system inaccessible to its intended and legitimate users. Unlike other vulnerabilities, DoS attacks usually do not aim at breaching security. Rather, they are focused on making websites and services unavailable to genuine users resulting in downtime. One popular Denial of Service vulnerability is DDoS (a Distributed Denial of Service), an attack that attempts to clog network pipes to the system by generating a large volume of traffic from many machines. When it comes to open source libraries, DoS vulnerabilities allow attackers to trigger such a crash or crippling of the service by using a flaw either in the application code or from the use of open source libraries. Two common types of DoS vulnerabilities: High CPU/Memory Consumption- An attacker sending crafted requests that could cause the system to take a disproportionate amount of time to process. For example, commons-fileupload:commons-fileupload . Crash - An attacker sending crafted requests that could cause the system to crash. For Example, npm ws package ",
        "Overview": "apache-airflow is a platform to programmatically author, schedule, and monitor workflows. Affected versions of this package are vulnerable to Denial of Service (DoS) allowing an attacker to cause a service disruption by manipulating the run_id parameter. "
    },
    "source_code": [
        {
            "filename": "airflow/config_templates/config.yml",
            "diff": "@@ -2440,6 +2440,15 @@ scheduler:\n       type: float\n       example: ~\n       default: \"120.0\"\n+    allowed_run_id_pattern:\n+      description: |\n+        The run_id pattern used to verify the validity of user input to the run_id parameter when\n+        triggering a DAG. This pattern cannot change the pattern used by scheduler to generate run_id\n+        for scheduled DAG runs or DAG runs triggered without changing the run_id parameter.\n+      version_added: 2.6.3\n+      type: string\n+      example: ~\n+      default: \"^[A-Za-z0-9_.~:+-]+$\"\n triggerer:\n   description: ~\n   options:"
        },
        {
            "filename": "airflow/config_templates/default_airflow.cfg",
            "diff": "@@ -1245,6 +1245,11 @@ task_queued_timeout = 600.0\n # longer than `[scheduler] task_queued_timeout`.\n task_queued_timeout_check_interval = 120.0\n \n+# The run_id pattern used to verify the validity of user input to the run_id parameter when\n+# triggering a DAG. This pattern cannot change the pattern used by scheduler to generate run_id\n+# for scheduled DAG runs or DAG runs triggered without changing the run_id parameter.\n+allowed_run_id_pattern = ^[A-Za-z0-9_.~:+-]+$\n+\n [triggerer]\n # How many triggers a single Triggerer will run at once, by default.\n default_capacity = 1000"
        },
        {
            "filename": "airflow/models/dag.py",
            "diff": "@@ -66,7 +66,7 @@\n from airflow import settings, utils\n from airflow.api_internal.internal_api_call import internal_api_call\n from airflow.compat.functools import cached_property\n-from airflow.configuration import conf, secrets_backend_list\n+from airflow.configuration import conf as airflow_conf, secrets_backend_list\n from airflow.exceptions import (\n     AirflowDagInconsistent,\n     AirflowException,\n@@ -80,7 +80,7 @@\n from airflow.models.base import Base, StringID\n from airflow.models.dagcode import DagCode\n from airflow.models.dagpickle import DagPickle\n-from airflow.models.dagrun import DagRun\n+from airflow.models.dagrun import RUN_ID_REGEX, DagRun\n from airflow.models.operator import Operator\n from airflow.models.param import DagParam, ParamsDict\n from airflow.models.taskinstance import Context, TaskInstance, TaskInstanceKey, clear_task_instances\n@@ -402,13 +402,13 @@ def __init__(\n         user_defined_filters: dict | None = None,\n         default_args: dict | None = None,\n         concurrency: int | None = None,\n-        max_active_tasks: int = conf.getint(\"core\", \"max_active_tasks_per_dag\"),\n-        max_active_runs: int = conf.getint(\"core\", \"max_active_runs_per_dag\"),\n+        max_active_tasks: int = airflow_conf.getint(\"core\", \"max_active_tasks_per_dag\"),\n+        max_active_runs: int = airflow_conf.getint(\"core\", \"max_active_runs_per_dag\"),\n         dagrun_timeout: timedelta | None = None,\n         sla_miss_callback: None | SLAMissCallback | list[SLAMissCallback] = None,\n-        default_view: str = conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),\n-        orientation: str = conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),\n-        catchup: bool = conf.getboolean(\"scheduler\", \"catchup_by_default\"),\n+        default_view: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),\n+        orientation: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),\n+        catchup: bool = airflow_conf.getboolean(\"scheduler\", \"catchup_by_default\"),\n         on_success_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,\n         on_failure_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,\n         doc_md: str | None = None,\n@@ -2429,7 +2429,7 @@ def run(\n         mark_success=False,\n         local=False,\n         executor=None,\n-        donot_pickle=conf.getboolean(\"core\", \"donot_pickle\"),\n+        donot_pickle=airflow_conf.getboolean(\"core\", \"donot_pickle\"),\n         ignore_task_deps=False,\n         ignore_first_depends_on_past=True,\n         pool=None,\n@@ -2666,13 +2666,14 @@ def create_dagrun(\n                 \"Creating DagRun needs either `run_id` or both `run_type` and `execution_date`\"\n             )\n \n-        if run_id and \"/\" in run_id:\n-            warnings.warn(\n-                \"Using forward slash ('/') in a DAG run ID is deprecated. Note that this character \"\n-                \"also makes the run impossible to retrieve via Airflow's REST API.\",\n-                RemovedInAirflow3Warning,\n-                stacklevel=3,\n-            )\n+        regex = airflow_conf.get(\"scheduler\", \"allowed_run_id_pattern\")\n+\n+        if run_id and not re.match(RUN_ID_REGEX, run_id):\n+            if not regex.strip() or not re.match(regex.strip(), run_id):\n+                raise AirflowException(\n+                    f\"The provided run ID '{run_id}' is invalid. It does not match either \"\n+                    f\"the configured pattern: '{regex}' or the built-in pattern: '{RUN_ID_REGEX}'\"\n+                )\n \n         # create a copy of params before validating\n         copied_params = copy.deepcopy(self.params)\n@@ -2960,7 +2961,7 @@ def sync_to_db(self, processor_subdir: str | None = None, session=NEW_SESSION):\n     def get_default_view(self):\n         \"\"\"This is only there for backward compatible jinja2 templates\"\"\"\n         if self.default_view is None:\n-            return conf.get(\"webserver\", \"dag_default_view\").lower()\n+            return airflow_conf.get(\"webserver\", \"dag_default_view\").lower()\n         else:\n             return self.default_view\n \n@@ -3177,7 +3178,7 @@ class DagModel(Base):\n     root_dag_id = Column(StringID())\n     # A DAG can be paused from the UI / DB\n     # Set this default value of is_paused based on a configuration value!\n-    is_paused_at_creation = conf.getboolean(\"core\", \"dags_are_paused_at_creation\")\n+    is_paused_at_creation = airflow_conf.getboolean(\"core\", \"dags_are_paused_at_creation\")\n     is_paused = Column(Boolean, default=is_paused_at_creation)\n     # Whether the DAG is a subdag\n     is_subdag = Column(Boolean, default=False)\n@@ -3251,7 +3252,9 @@ class DagModel(Base):\n         \"TaskOutletDatasetReference\",\n         cascade=\"all, delete, delete-orphan\",\n     )\n-    NUM_DAGS_PER_DAGRUN_QUERY = conf.getint(\"scheduler\", \"max_dagruns_to_create_per_loop\", fallback=10)\n+    NUM_DAGS_PER_DAGRUN_QUERY = airflow_conf.getint(\n+        \"scheduler\", \"max_dagruns_to_create_per_loop\", fallback=10\n+    )\n \n     def __init__(self, concurrency=None, **kwargs):\n         super().__init__(**kwargs)\n@@ -3264,10 +3267,10 @@ def __init__(self, concurrency=None, **kwargs):\n                 )\n                 self.max_active_tasks = concurrency\n             else:\n-                self.max_active_tasks = conf.getint(\"core\", \"max_active_tasks_per_dag\")\n+                self.max_active_tasks = airflow_conf.getint(\"core\", \"max_active_tasks_per_dag\")\n \n         if self.max_active_runs is None:\n-            self.max_active_runs = conf.getint(\"core\", \"max_active_runs_per_dag\")\n+            self.max_active_runs = airflow_conf.getint(\"core\", \"max_active_runs_per_dag\")\n \n         if self.has_task_concurrency_limits is None:\n             # Be safe -- this will be updated later once the DAG is parsed\n@@ -3346,7 +3349,7 @@ def get_default_view(self) -> str:\n         have a value\n         \"\"\"\n         # This is for backwards-compatibility with old dags that don't have None as default_view\n-        return self.default_view or conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower()\n+        return self.default_view or airflow_conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower()\n \n     @property\n     def safe_dag_id(self):\n@@ -3529,13 +3532,13 @@ def dag(\n     user_defined_filters: dict | None = None,\n     default_args: dict | None = None,\n     concurrency: int | None = None,\n-    max_active_tasks: int = conf.getint(\"core\", \"max_active_tasks_per_dag\"),\n-    max_active_runs: int = conf.getint(\"core\", \"max_active_runs_per_dag\"),\n+    max_active_tasks: int = airflow_conf.getint(\"core\", \"max_active_tasks_per_dag\"),\n+    max_active_runs: int = airflow_conf.getint(\"core\", \"max_active_runs_per_dag\"),\n     dagrun_timeout: timedelta | None = None,\n     sla_miss_callback: None | SLAMissCallback | list[SLAMissCallback] = None,\n-    default_view: str = conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),\n-    orientation: str = conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),\n-    catchup: bool = conf.getboolean(\"scheduler\", \"catchup_by_default\"),\n+    default_view: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),\n+    orientation: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),\n+    catchup: bool = airflow_conf.getboolean(\"scheduler\", \"catchup_by_default\"),\n     on_success_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,\n     on_failure_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,\n     doc_md: str | None = None,"
        },
        {
            "filename": "airflow/models/dagrun.py",
            "diff": "@@ -24,6 +24,7 @@\n from datetime import datetime\n from typing import TYPE_CHECKING, Any, Callable, Iterable, Iterator, NamedTuple, Sequence, TypeVar, overload\n \n+import re2 as re\n from sqlalchemy import (\n     Boolean,\n     Column,\n@@ -43,7 +44,7 @@\n )\n from sqlalchemy.exc import IntegrityError\n from sqlalchemy.ext.associationproxy import association_proxy\n-from sqlalchemy.orm import Session, declared_attr, joinedload, relationship, synonym\n+from sqlalchemy.orm import Session, declared_attr, joinedload, relationship, synonym, validates\n from sqlalchemy.sql.expression import false, select, true\n \n from airflow import settings\n@@ -75,6 +76,8 @@\n     CreatedTasks = TypeVar(\"CreatedTasks\", Iterator[\"dict[str, Any]\"], Iterator[TI])\n     TaskCreator = Callable[[Operator, Iterable[int]], CreatedTasks]\n \n+RUN_ID_REGEX = r\"^(?:manual|scheduled|dataset_triggered)__(?:\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\+00:00)$\"\n+\n \n class TISchedulingDecision(NamedTuple):\n     \"\"\"Type of return for DagRun.task_instance_scheduling_decisions\"\"\"\n@@ -238,6 +241,17 @@ def __repr__(self):\n             external_trigger=self.external_trigger,\n         )\n \n+    @validates(\"run_id\")\n+    def validate_run_id(self, key: str, run_id: str) -> str | None:\n+        if not run_id:\n+            return None\n+        regex = airflow_conf.get(\"scheduler\", \"allowed_run_id_pattern\")\n+        if not re.match(regex, run_id) and not re.match(RUN_ID_REGEX, run_id):\n+            raise ValueError(\n+                f\"The run_id provided '{run_id}' does not match the pattern '{regex}' or '{RUN_ID_REGEX}'\"\n+            )\n+        return run_id\n+\n     @property\n     def logical_date(self) -> datetime:\n         return self.execution_date"
        },
        {
            "filename": "airflow/www/views.py",
            "diff": "@@ -96,7 +96,7 @@\n from airflow.models.abstractoperator import AbstractOperator\n from airflow.models.dag import DAG, get_dataset_triggered_next_run_info\n from airflow.models.dagcode import DagCode\n-from airflow.models.dagrun import DagRun, DagRunType\n+from airflow.models.dagrun import RUN_ID_REGEX, DagRun, DagRunType\n from airflow.models.dataset import DagScheduleDatasetReference, DatasetDagRunQueue, DatasetEvent, DatasetModel\n from airflow.models.mappedoperator import MappedOperator\n from airflow.models.operator import Operator\n@@ -1896,7 +1896,7 @@ def delete(self):\n     def trigger(self, session: Session = NEW_SESSION):\n         \"\"\"Triggers DAG Run.\"\"\"\n         dag_id = request.values[\"dag_id\"]\n-        run_id = request.values.get(\"run_id\", \"\")\n+        run_id = request.values.get(\"run_id\", \"\").replace(\" \", \"+\")\n         origin = get_safe_url(request.values.get(\"origin\"))\n         unpause = request.values.get(\"unpause\")\n         request_conf = request.values.get(\"conf\")\n@@ -2016,13 +2016,27 @@ def trigger(self, session: Session = NEW_SESSION):\n             flash(message, \"error\")\n             return redirect(origin)\n \n-        # Flash a warning when slash is used, but still allow it to continue on.\n-        if run_id and \"/\" in run_id:\n-            flash(\n-                \"Using forward slash ('/') in a DAG run ID is deprecated. Note that this character \"\n-                \"also makes the run impossible to retrieve via Airflow's REST API.\",\n-                \"warning\",\n-            )\n+        regex = conf.get(\"scheduler\", \"allowed_run_id_pattern\")\n+        if run_id and not re.match(RUN_ID_REGEX, run_id):\n+            if not regex.strip() or not re.match(regex.strip(), run_id):\n+                flash(\n+                    f\"The provided run ID '{run_id}' is invalid. It does not match either \"\n+                    f\"the configured pattern: '{regex}' or the built-in pattern: '{RUN_ID_REGEX}'\",\n+                    \"error\",\n+                )\n+\n+                form = DateTimeForm(data={\"execution_date\": execution_date})\n+                return self.render_template(\n+                    \"airflow/trigger.html\",\n+                    form_fields=form_fields,\n+                    dag=dag,\n+                    dag_id=dag_id,\n+                    origin=origin,\n+                    conf=request_conf,\n+                    form=form,\n+                    is_dag_run_conf_overrides_params=is_dag_run_conf_overrides_params,\n+                    recent_confs=recent_confs,\n+                )\n \n         run_conf = {}\n         if request_conf:"
        },
        {
            "filename": "tests/models/test_dagrun.py",
            "diff": "@@ -29,6 +29,7 @@\n from airflow import settings\n from airflow.callbacks.callback_requests import DagCallbackRequest\n from airflow.decorators import task, task_group\n+from airflow.exceptions import AirflowException\n from airflow.models import (\n     DAG,\n     DagBag,\n@@ -53,6 +54,7 @@\n from airflow.utils.types import DagRunType\n from tests.models import DEFAULT_DATE as _DEFAULT_DATE\n from tests.test_utils import db\n+from tests.test_utils.config import conf_vars\n from tests.test_utils.mock_operators import MockOperator\n \n DEFAULT_DATE = pendulum.instance(_DEFAULT_DATE)\n@@ -2328,3 +2330,33 @@ def the_task():\n \n     assert session.query(DagRun).filter(DagRun.id == dr.id).one_or_none() is None\n     assert session.query(DagRunNote).filter(DagRunNote.dag_run_id == dr.id).one_or_none() is None\n+\n+\n+@pytest.mark.parametrize(\n+    \"pattern, run_id, result\",\n+    [\n+        [\"^[A-Z]\", \"ABC\", True],\n+        [\"^[A-Z]\", \"abc\", False],\n+        [\"^[0-9]\", \"123\", True],\n+        # The below params tests that user configuration does not affect internally generated\n+        # run_ids\n+        [\"\", \"scheduled__2023-01-01T00:00:00+00:00\", True],\n+        [\"\", \"manual__2023-01-01T00:00:00+00:00\", True],\n+        [\"\", \"dataset_triggered__2023-01-01T00:00:00+00:00\", True],\n+        [\"\", \"scheduled_2023-01-01T00\", False],\n+        [\"\", \"manual_2023-01-01T00\", False],\n+        [\"\", \"dataset_triggered_2023-01-01T00\", False],\n+        [\"^[0-9]\", \"scheduled__2023-01-01T00:00:00+00:00\", True],\n+        [\"^[0-9]\", \"manual__2023-01-01T00:00:00+00:00\", True],\n+        [\"^[a-z]\", \"dataset_triggered__2023-01-01T00:00:00+00:00\", True],\n+    ],\n+)\n+def test_dag_run_id_config(session, dag_maker, pattern, run_id, result):\n+    with conf_vars({(\"scheduler\", \"allowed_run_id_pattern\"): pattern}):\n+        with dag_maker():\n+            ...\n+        if result:\n+            dag_maker.create_dagrun(run_id=run_id)\n+        else:\n+            with pytest.raises(AirflowException):\n+                dag_maker.create_dagrun(run_id=run_id)"
        },
        {
            "filename": "tests/www/views/test_views_trigger_dag.py",
            "diff": "@@ -30,6 +30,7 @@\n from airflow.utils.session import create_session\n from airflow.utils.types import DagRunType\n from tests.test_utils.api_connexion_utils import create_test_client\n+from tests.test_utils.config import conf_vars\n from tests.test_utils.www import check_content_in_response\n \n \n@@ -286,3 +287,32 @@ def test_trigger_dag_params_array_value_none_render(admin_client, dag_maker, ses\n         f'<textarea style=\"display: none;\" id=\"json_start\" name=\"json_start\">{expected_dag_conf}</textarea>',\n         resp,\n     )\n+\n+\n+@pytest.mark.parametrize(\n+    \"pattern, run_id, result\",\n+    [\n+        [\"^[A-Z]\", \"ABC\", True],\n+        [\"^[A-Z]\", \"abc\", False],\n+        [\"^[0-9]\", \"123\", True],\n+        # The below params tests that user configuration does not affect internally generated\n+        # run_ids. We use manual__ as a prefix for manually triggered DAGs due to a restriction\n+        # in manually triggered DAGs that the run_id must not start with scheduled__.\n+        [\"\", \"manual__2023-01-01T00:00:00+00:00\", True],\n+        [\"\", \"scheduled_2023-01-01T00\", False],\n+        [\"\", \"manual_2023-01-01T00\", False],\n+        [\"\", \"dataset_triggered_2023-01-01T00\", False],\n+        [\"^[0-9]\", \"manual__2023-01-01T00:00:00+00:00\", True],\n+        [\"^[a-z]\", \"manual__2023-01-01T00:00:00+00:00\", True],\n+    ],\n+)\n+def test_dag_run_id_pattern(session, admin_client, pattern, run_id, result):\n+    with conf_vars({(\"scheduler\", \"allowed_run_id_pattern\"): pattern}):\n+        test_dag_id = \"example_bash_operator\"\n+        admin_client.post(f\"dags/{test_dag_id}/trigger?&run_id={run_id}\")\n+        run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()\n+        if result:\n+            assert run is not None\n+            assert run.run_type == DagRunType.MANUAL\n+        else:\n+            assert run is None"
        }
    ],
    "commitTime": "2023-07-06 22:25:41"
}