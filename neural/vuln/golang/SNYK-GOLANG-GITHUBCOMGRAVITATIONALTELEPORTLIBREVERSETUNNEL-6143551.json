{
    "CVSSv3": {
        "CVSS": "3.1",
        "attackVector": "NETWORK",
        "attackComplexity": "LOW",
        "privilegesRequired": "LOW",
        "userInteraction": "NONE",
        "scope": "UNCHANGED",
        "confidentiality": "HIGH",
        "integrity": "HIGH",
        "availability": "NONE"
    },
    "credit": [
        "Tener"
    ],
    "cvssDetails": [],
    "cvssScore": 8.1,
    "disclosureTime": "2024-01-03 21:28:37",
    "epssDetails": null,
    "exploitMaturity": "Not Defined",
    "id": "SNYK-GOLANG-GITHUBCOMGRAVITATIONALTELEPORTLIBREVERSETUNNEL-6143551",
    "identifiers": {
        "CVE": [],
        "CWE": [
            "CWE-918"
        ]
    },
    "language": "golang",
    "malicious": false,
    "packageManager": "golang",
    "publicationTime": "2024-01-04 11:02:27",
    "remediation": "Upgrade github.com/gravitational/teleport/lib/reversetunnel to version 12.4.31, 13.4.13, 14.2.4 or higher. ",
    "severity": "high",
    "socialTrendAlert": false,
    "title": "Server-Side Request Forgery (SSRF)",
    "vulnDescription": {
        "Overview": "Affected versions of this package are vulnerable to Server-Side Request Forgery (SSRF) via the proxy and/or agents. An attacker with valid credentials, user or host, can perform non-blind requests to arbitrary hosts, potentially leading to unauthorized access or information disclosure. ",
        "Workaround": "Strict network controls from the Teleport Proxy and Teleport Agents reduce the potential exposure from this issue. The maintainers recommend restricting outbound network connections to only the Auth Service, your SSO provider, and any agents, databases, or applications needed to be accessed from the proxy. If running in a cloud environment, pay careful attention to what cloud resources are accessible from the proxy. "
    },
    "source_code": [
        {
            "filename": "lib/reversetunnel/agent.go",
            "diff": "@@ -62,10 +62,10 @@ const (\n // AgentStateCallback is called when an agent's state changes.\n type AgentStateCallback func(AgentState)\n \n-// transporter handles the creation of new transports over ssh.\n-type transporter interface {\n-\t// Transport creates a new transport.\n-\ttransport(context.Context, ssh.Channel, <-chan *ssh.Request, sshutils.Conn) *transport\n+// transportHandler handles the creation of new transports over ssh.\n+type transportHandler interface {\n+\t// handleTransport runs the receiver of a teleport-transport channel.\n+\thandleTransport(context.Context, ssh.Channel, <-chan *ssh.Request, sshutils.Conn)\n }\n \n // sshDialer is an ssh dialer that returns an SSHClient\n@@ -102,8 +102,8 @@ type agentConfig struct {\n \tstateCallback AgentStateCallback\n \t// sshDialer creates a new ssh connection.\n \tsshDialer sshDialer\n-\t// transporter creates a new transport.\n-\ttransporter transporter\n+\t// transportHandler handles teleport-transport channels.\n+\ttransportHandler transportHandler\n \t// versionGetter gets the connected auth server version.\n \tversionGetter versionGetter\n \t// tracker tracks existing proxies.\n@@ -130,8 +130,8 @@ func (c *agentConfig) checkAndSetDefaults() error {\n \tif c.sshDialer == nil {\n \t\treturn trace.BadParameter(\"missing parameter sshDialer\")\n \t}\n-\tif c.transporter == nil {\n-\t\treturn trace.BadParameter(\"missing parameter transporter\")\n+\tif c.transportHandler == nil {\n+\t\treturn trace.BadParameter(\"missing parameter transportHandler\")\n \t}\n \tif c.versionGetter == nil {\n \t\treturn trace.BadParameter(\"missing parameter versionGetter\")\n@@ -579,12 +579,10 @@ func (a *agent) handleDrainChannels() error {\n \t\t\t\tcontinue\n \t\t\t}\n \n-\t\t\tt := a.transporter.transport(a.ctx, ch, req, a.client)\n-\n \t\t\ta.drainWG.Add(1)\n \t\t\tgo func() {\n-\t\t\t\tt.start()\n-\t\t\t\ta.drainWG.Done()\n+\t\t\t\tdefer a.drainWG.Done()\n+\t\t\t\ta.transportHandler.handleTransport(a.ctx, ch, req, a.client)\n \t\t\t}()\n \n \t\t}"
        },
        {
            "filename": "lib/reversetunnel/agent_test.go",
            "diff": "@@ -142,8 +142,7 @@ type mockAgentInjection struct {\n \tclient SSHClient\n }\n \n-func (m *mockAgentInjection) transport(context.Context, ssh.Channel, <-chan *ssh.Request, sshutils.Conn) *transport {\n-\treturn &transport{}\n+func (m *mockAgentInjection) handleTransport(context.Context, ssh.Channel, <-chan *ssh.Request, sshutils.Conn) {\n }\n \n func (m *mockAgentInjection) DialContext(context.Context, utils.NetAddr) (SSHClient, error) {\n@@ -176,13 +175,13 @@ func testAgent(t *testing.T) (*agent, *mockSSHClient) {\n \t}\n \n \tagent, err := newAgent(agentConfig{\n-\t\tkeepAlive:     time.Millisecond * 100,\n-\t\taddr:          addr,\n-\t\ttransporter:   inject,\n-\t\tsshDialer:     inject,\n-\t\tversionGetter: inject,\n-\t\ttracker:       tracker,\n-\t\tlease:         lease,\n+\t\tkeepAlive:        time.Millisecond * 100,\n+\t\taddr:             addr,\n+\t\ttransportHandler: inject,\n+\t\tsshDialer:        inject,\n+\t\tversionGetter:    inject,\n+\t\ttracker:          tracker,\n+\t\tlease:            lease,\n \t})\n \trequire.NoError(t, err, \"Unexpected error during agent construction.\")\n "
        },
        {
            "filename": "lib/reversetunnel/agentpool.go",
            "diff": "@@ -23,6 +23,7 @@ import (\n \t\"crypto/tls\"\n \t\"crypto/x509\"\n \t\"errors\"\n+\t\"fmt\"\n \t\"io\"\n \t\"net\"\n \t\"sync\"\n@@ -37,6 +38,7 @@ import (\n \t\"github.com/gravitational/teleport/api/client\"\n \t\"github.com/gravitational/teleport/api/client/webclient\"\n \t\"github.com/gravitational/teleport/api/defaults\"\n+\tapidefaults \"github.com/gravitational/teleport/api/defaults\"\n \t\"github.com/gravitational/teleport/api/types\"\n \t\"github.com/gravitational/teleport/api/utils/retryutils\"\n \t\"github.com/gravitational/teleport/api/utils/sshutils\"\n@@ -464,7 +466,7 @@ func (p *AgentPool) newAgent(ctx context.Context, tracker *track.Tracker, lease\n \t\taddr:               *addr,\n \t\tkeepAlive:          p.runtimeConfig.keepAliveInterval,\n \t\tsshDialer:          dialer,\n-\t\ttransporter:        p,\n+\t\ttransportHandler:   p,\n \t\tversionGetter:      p,\n \t\ttracker:            tracker,\n \t\tlease:              lease,\n@@ -515,8 +517,13 @@ func (p *AgentPool) getVersion(ctx context.Context) (string, error) {\n \treturn pong.ServerVersion, nil\n }\n \n-// transport creates a new transport instance.\n-func (p *AgentPool) transport(ctx context.Context, channel ssh.Channel, requests <-chan *ssh.Request, conn sshutils.Conn) *transport {\n+// handleTransport runs a new teleport-transport channel.\n+func (p *AgentPool) handleTransport(ctx context.Context, channel ssh.Channel, requests <-chan *ssh.Request, conn sshutils.Conn) {\n+\tif !p.IsRemoteCluster {\n+\t\tp.handleLocalTransport(ctx, channel, requests, conn)\n+\t\treturn\n+\t}\n+\n \tt := &transport{\n \t\tcloseContext:         ctx,\n \t\tcomponent:            p.Component,\n@@ -540,11 +547,63 @@ func (p *AgentPool) transport(ctx context.Context, channel ssh.Channel, requests\n \t// the leaf proxy to track sessions that are initiated via the root cluster. Without providing\n \t// the user tracker the leaf cluster metrics will be incorrect and graceful shutdown will not\n \t// wait for user sessions to be terminated prior to proceeding with the shutdown operation.\n-\tif p.IsRemoteCluster && p.ReverseTunnelServer != nil {\n+\tif p.ReverseTunnelServer != nil {\n \t\tt.trackUserConnection = p.ReverseTunnelServer.TrackUserConnection\n \t}\n \n-\treturn t\n+\tt.start()\n+}\n+\n+func (p *AgentPool) handleLocalTransport(ctx context.Context, channel ssh.Channel, reqC <-chan *ssh.Request, sconn sshutils.Conn) {\n+\tdefer channel.Close()\n+\tgo io.Copy(io.Discard, channel.Stderr())\n+\n+\t// the only valid teleport-transport-dial request here is to reach the local service\n+\tvar req *ssh.Request\n+\tselect {\n+\tcase <-ctx.Done():\n+\t\tgo ssh.DiscardRequests(reqC)\n+\t\treturn\n+\tcase <-time.After(apidefaults.DefaultIOTimeout):\n+\t\tgo ssh.DiscardRequests(reqC)\n+\t\tp.log.Warn(\"Timed out waiting for transport dial request.\")\n+\t\treturn\n+\tcase r, ok := <-reqC:\n+\t\tif !ok {\n+\t\t\treturn\n+\t\t}\n+\t\tgo ssh.DiscardRequests(reqC)\n+\t\treq = r\n+\t}\n+\n+\t// sconn should never be nil, but it's sourced from the agent state and\n+\t// starts as nil, and the original transport code checked against it\n+\tif sconn == nil || p.Server == nil {\n+\t\tp.log.Error(\"Missing client or server (this is a bug).\")\n+\t\tfmt.Fprintf(channel.Stderr(), \"internal server error\")\n+\t\treq.Reply(false, nil)\n+\t\treturn\n+\t}\n+\n+\tif err := req.Reply(true, nil); err != nil {\n+\t\tp.log.Errorf(\"Failed to respond to dial request: %v.\", err)\n+\t\treturn\n+\t}\n+\n+\tvar conn net.Conn = sshutils.NewChConn(sconn, channel)\n+\n+\tdialReq := parseDialReq(req.Payload)\n+\tswitch dialReq.Address {\n+\tcase reversetunnelclient.LocalNode, reversetunnelclient.LocalKubernetes, reversetunnelclient.LocalWindowsDesktop:\n+\tdefault:\n+\t\tp.log.WithField(\"address\", dialReq.Address).\n+\t\t\tWarn(\"Received dial request for unexpected address, routing to the local service anyway.\")\n+\t}\n+\tif src, err := utils.ParseAddr(dialReq.ClientSrcAddr); err == nil {\n+\t\tconn = utils.NewConnWithSrcAddr(conn, getTCPAddr(src))\n+\t}\n+\n+\tp.Server.HandleConnection(conn)\n }\n \n // agentPoolRuntimeConfig contains configurations dynamically set and updated"
        },
        {
            "filename": "lib/reversetunnel/srv.go",
            "diff": "@@ -37,6 +37,7 @@ import (\n \t\"github.com/gravitational/teleport\"\n \t\"github.com/gravitational/teleport/api/breaker\"\n \t\"github.com/gravitational/teleport/api/constants\"\n+\tapidefaults \"github.com/gravitational/teleport/api/defaults\"\n \t\"github.com/gravitational/teleport/api/types\"\n \t\"github.com/gravitational/teleport/api/utils/retryutils\"\n \tapisshutils \"github.com/gravitational/teleport/api/utils/sshutils\"\n@@ -669,28 +670,92 @@ func (s *server) HandleNewChan(ctx context.Context, ccx *sshutils.ConnectionCont\n }\n \n func (s *server) handleTransport(sconn *ssh.ServerConn, nch ssh.NewChannel) {\n-\ts.log.Debugf(\"Transport request: %v.\", nch.ChannelType())\n-\tchannel, requestCh, err := nch.Accept()\n+\ts.log.Debug(\"Received transport request.\")\n+\tchannel, requestC, err := nch.Accept()\n \tif err != nil {\n \t\tsconn.Close()\n+\t\t// avoid WithError to reduce log spam on network errors\n \t\ts.log.Warnf(\"Failed to accept request: %v.\", err)\n \t\treturn\n \t}\n \n-\tt := &transport{\n-\t\tlog:              s.log,\n-\t\tcloseContext:     s.ctx,\n-\t\tauthClient:       s.LocalAccessPoint,\n-\t\tauthServers:      s.LocalAuthAddresses,\n-\t\tchannel:          channel,\n-\t\trequestCh:        requestCh,\n-\t\tcomponent:        teleport.ComponentReverseTunnelServer,\n-\t\tlocalClusterName: s.ClusterName,\n-\t\temitter:          s.Emitter,\n-\t\tproxySigner:      s.proxySigner,\n-\t\tsconn:            sconn,\n-\t}\n-\tgo t.start()\n+\tgo s.handleTransportChannel(sconn, channel, requestC)\n+}\n+\n+func (s *server) handleTransportChannel(sconn *ssh.ServerConn, ch ssh.Channel, reqC <-chan *ssh.Request) {\n+\tdefer ch.Close()\n+\tgo io.Copy(io.Discard, ch.Stderr())\n+\n+\t// the only valid teleport-transport-dial request here is to reach the auth server\n+\tvar req *ssh.Request\n+\tselect {\n+\tcase <-s.ctx.Done():\n+\t\tgo ssh.DiscardRequests(reqC)\n+\t\treturn\n+\tcase <-time.After(apidefaults.DefaultIOTimeout):\n+\t\tgo ssh.DiscardRequests(reqC)\n+\t\ts.log.Warn(\"Timed out waiting for transport dial request.\")\n+\t\treturn\n+\tcase r, ok := <-reqC:\n+\t\tif !ok {\n+\t\t\treturn\n+\t\t}\n+\t\tgo ssh.DiscardRequests(reqC)\n+\t\treq = r\n+\t}\n+\n+\tdialReq := parseDialReq(req.Payload)\n+\tif dialReq.Address != constants.RemoteAuthServer {\n+\t\ts.log.WithField(\"address\", dialReq.Address).\n+\t\t\tWarn(\"Received dial request for unexpected address, routing to the auth server anyway.\")\n+\t}\n+\n+\tauthAddress := utils.ChooseRandomString(s.LocalAuthAddresses)\n+\tif authAddress == \"\" {\n+\t\ts.log.Error(\"No auth servers configured.\")\n+\t\tfmt.Fprint(ch.Stderr(), \"internal server error\")\n+\t\treq.Reply(false, nil)\n+\t\treturn\n+\t}\n+\n+\tvar proxyHeader []byte\n+\tclientSrcAddr := sconn.RemoteAddr()\n+\tclientDstAddr := sconn.LocalAddr()\n+\tif s.proxySigner != nil && clientSrcAddr != nil && clientDstAddr != nil {\n+\t\th, err := s.proxySigner.SignPROXYHeader(clientSrcAddr, clientDstAddr)\n+\t\tif err != nil {\n+\t\t\ts.log.WithError(err).Error(\"Failed to create signed PROXY header.\")\n+\t\t\tfmt.Fprint(ch.Stderr(), \"internal server error\")\n+\t\t\treq.Reply(false, nil)\n+\t\t}\n+\t\tproxyHeader = h\n+\t}\n+\n+\td := net.Dialer{Timeout: apidefaults.DefaultIOTimeout}\n+\tconn, err := d.DialContext(s.ctx, \"tcp\", authAddress)\n+\tif err != nil {\n+\t\ts.log.Errorf(\"Failed to dial auth: %v.\", err)\n+\t\tfmt.Fprint(ch.Stderr(), \"failed to dial auth server\")\n+\t\treq.Reply(false, nil)\n+\t\treturn\n+\t}\n+\tdefer conn.Close()\n+\n+\t_ = conn.SetWriteDeadline(time.Now().Add(apidefaults.DefaultIOTimeout))\n+\tif _, err := conn.Write(proxyHeader); err != nil {\n+\t\ts.log.Errorf(\"Failed to send PROXY header: %v.\", err)\n+\t\tfmt.Fprint(ch.Stderr(), \"failed to dial auth server\")\n+\t\treq.Reply(false, nil)\n+\t\treturn\n+\t}\n+\t_ = conn.SetWriteDeadline(time.Time{})\n+\n+\tif err := req.Reply(true, nil); err != nil {\n+\t\ts.log.Errorf(\"Failed to respond to dial request: %v.\", err)\n+\t\treturn\n+\t}\n+\n+\t_ = utils.ProxyConn(s.ctx, ch, conn)\n }\n \n // TODO(awly): unit test this"
        },
        {
            "filename": "lib/reversetunnel/srv_test.go",
            "diff": "@@ -20,14 +20,18 @@ package reversetunnel\n \n import (\n \t\"context\"\n+\t\"crypto/ed25519\"\n \t\"encoding/json\"\n \t\"errors\"\n+\t\"io\"\n \t\"net\"\n \t\"testing\"\n \t\"time\"\n \n \t\"github.com/google/go-cmp/cmp\"\n \t\"github.com/jonboulle/clockwork\"\n+\t\"github.com/sirupsen/logrus\"\n+\t\"github.com/stretchr/testify/assert\"\n \t\"github.com/stretchr/testify/require\"\n \t\"golang.org/x/crypto/ssh\"\n \n@@ -269,3 +273,144 @@ func Test_ParseDialReq(t *testing.T) {\n \t\trequire.Equal(t, &test, parsed)\n \t}\n }\n+\n+// TestOnlyAuthDial checks if [reversetunnel.server]'s handling of the\n+// teleport-transport channel prevents dialing arbitrary addresses and only\n+// allows dialing the auth server.\n+func TestOnlyAuthDial(t *testing.T) {\n+\tctx, cancel := context.WithCancel(context.Background())\n+\tt.Cleanup(cancel)\n+\n+\tgoodListenerAddr := acceptAndCloseListener(t, false)\n+\tbadListenerAddr := acceptAndCloseListener(t, true)\n+\n+\tsrv := &server{\n+\t\tlog: logrus.StandardLogger(),\n+\t\tctx: ctx,\n+\t\tConfig: Config{\n+\t\t\tLocalAuthAddresses: []string{goodListenerAddr},\n+\t\t},\n+\t}\n+\n+\tserverConn, clientConn := sshPipe(t)\n+\n+\tgo func() {\n+\t\tfor nc := range serverConn.newChC {\n+\t\t\tgo srv.handleTransport(&ssh.ServerConn{Conn: serverConn.conn}, nc)\n+\t\t}\n+\t}()\n+\n+\tfor name, addr := range map[string]string{\n+\t\t\"RemoteAuthServer\": constants.RemoteAuthServer,\n+\t\t\"ArbitraryDial\":    badListenerAddr,\n+\t} {\n+\t\taddr := addr\n+\t\tt.Run(name, func(t *testing.T) {\n+\t\t\tch, reqC, err := clientConn.conn.OpenChannel(constants.ChanTransport, nil)\n+\t\t\trequire.NoError(t, err)\n+\t\t\tgo ssh.DiscardRequests(reqC)\n+\t\t\tgo io.Copy(io.Discard, ch.Stderr())\n+\t\t\tt.Cleanup(func() { ch.Close() })\n+\n+\t\t\tok, err := ch.SendRequest(constants.ChanTransportDialReq, true, []byte(addr))\n+\t\t\trequire.NoError(t, err)\n+\t\t\trequire.True(t, ok)\n+\n+\t\t\tbomb := time.AfterFunc(10*time.Second, func() { ch.Close() })\n+\t\t\tt.Cleanup(func() {\n+\t\t\t\trequire.True(t, bomb.Stop(), \"timed out waiting for remote close\")\n+\t\t\t})\n+\n+\t\t\t// block until the remote side closes the connection, which means\n+\t\t\t// that the upstream closed the connection, which means that if the\n+\t\t\t// listener wants to fail the test it has a chance to\n+\t\t\tio.Copy(io.Discard, ch)\n+\t\t})\n+\t}\n+}\n+\n+type sshConn struct {\n+\tconn   ssh.Conn\n+\tnewChC <-chan ssh.NewChannel\n+\treqC   <-chan *ssh.Request\n+}\n+\n+func sshPipe(t *testing.T) (sshConn, sshConn) {\n+\tc1, c2, err := utils.DualPipeNetConn(&net.TCPAddr{}, &net.TCPAddr{})\n+\trequire.NoError(t, err)\n+\tt.Cleanup(func() { c1.Close() })\n+\tt.Cleanup(func() { c2.Close() })\n+\n+\t// look ma, no randomness\n+\tsigner, err := ssh.NewSignerFromKey(ed25519.NewKeyFromSeed(make([]byte, ed25519.SeedSize)))\n+\trequire.NoError(t, err)\n+\n+\tcfg := &ssh.ServerConfig{NoClientAuth: true}\n+\tcfg.AddHostKey(signer)\n+\n+\tretC := make(chan sshConn, 2)\n+\tgo func() {\n+\t\tc, nc, r, err := ssh.NewServerConn(c1, cfg)\n+\t\tassert.NoError(t, err)\n+\t\tretC <- sshConn{\n+\t\t\tconn:   c,\n+\t\t\tnewChC: nc,\n+\t\t\treqC:   r,\n+\t\t}\n+\t}()\n+\tgo func() {\n+\t\tc, nc, r, err := ssh.NewClientConn(c2, \"\", &ssh.ClientConfig{\n+\t\t\tUser:            \"a\",\n+\t\t\tHostKeyCallback: ssh.InsecureIgnoreHostKey(),\n+\t\t})\n+\t\tassert.NoError(t, err)\n+\t\tretC <- sshConn{\n+\t\t\tconn:   c,\n+\t\t\tnewChC: nc,\n+\t\t\treqC:   r,\n+\t\t}\n+\t}()\n+\tp1 := <-retC\n+\tp2 := <-retC\n+\tif t.Failed() {\n+\t\tt.FailNow()\n+\t}\n+\n+\tsetupCleanup := func(p sshConn) {\n+\t\tt.Cleanup(func() {\n+\t\t\tgo ssh.DiscardRequests(p.reqC)\n+\t\t\tgo func() {\n+\t\t\t\tfor nc := range p.newChC {\n+\t\t\t\t\tnc.Reject(0, \"\")\n+\t\t\t\t}\n+\t\t\t}()\n+\t\t\tp.conn.Close()\n+\t\t\tp.conn.Wait()\n+\t\t})\n+\t}\n+\tsetupCleanup(p1)\n+\tsetupCleanup(p2)\n+\n+\treturn p1, p2\n+}\n+\n+func acceptAndCloseListener(t *testing.T, fail bool) (addr string) {\n+\tl, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n+\trequire.NoError(t, err)\n+\tt.Cleanup(func() { l.Close() })\n+\n+\tgo func() {\n+\t\tfor {\n+\t\t\tc, err := l.Accept()\n+\t\t\tif err != nil {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\tif fail {\n+\t\t\t\tassert.Fail(t, \"unexpected connection received\")\n+\t\t\t}\n+\t\t\tc.Close()\n+\t\t}\n+\t}()\n+\n+\treturn l.Addr().String()\n+}"
        }
    ],
    "commitTime": "2023-12-29 18:31:06"
}